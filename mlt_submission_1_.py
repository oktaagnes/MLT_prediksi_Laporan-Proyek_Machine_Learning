# -*- coding: utf-8 -*-
"""MLT Submission 1 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EHSiTvzPQ6oBcDI8BSqR6XrjozYguGSi

# Predictive Analysis : <span style="font-weight:normal">Prediksi Pemilihan Jenis Tanaman untuk Lahan Pertanian Tertentu</span>

<hr style="border:1px solid gray">

#### <span style="font-weight:normal">Proyek Submission 1 - Machine Learning Terapan <br/><br/> Oleh: Okta Agnes L. Manik</span>
"""

pip install xgboost

"""#Import Library"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import plotly.graph_objects as go
import plotly.express as px
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error

from plotly.subplots import make_subplots
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import LocalOutlierFactor
from sklearn.model_selection import train_test_split

from sklearn.neighbors import  KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report

"""#Data Understanding

## Menghubungkan dengan penyimpanan Google Drive
"""

from google.colab import drive
drive.mount('/content/drive/')

"""cek letak data disimpan"""

import os
print(os.listdir('/content/drive/MyDrive/dicoding'))

file_path = '/content/drive/MyDrive/dicoding/land_recommendation.csv'

# membaca dataset
land_df = pd.read_csv(file_path)
land_df.head(3)

"""Memuat info Jumlah Baris dan Jumlah Kolom di dataset credit_card"""

rows, cols = land_df.shape
print(f"Jumlah baris: {rows}")
print(f"Jumlah kolom: {cols}")

"""#### <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight:**<br>Output dari kode diatas memberikan informasi sebagai berikut:<br><ul><li>Terdapat 2200 baris dalam dataset.</li><li>Terdapat 8 kolom yaitu, N, P, K, Temperature, Humadity, ph, rainfall, dan label.</li></ul></span></div>"""

label = land_df['label'].drop_duplicates().values
label

"""# **Exploratory Data Analysis (EDA)**

###Memuat Info/type kolom pada dataset
"""

land_df.info()

"""#### <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight:**<br>Output dari kode diatas memberikan informasi sebagai berikut:<br><ul><li>Terdapat 3 kolom numerik dengan tipe data int64, yaitu: N, P, K. Ini merupakan fitur numerik.</li><li>Terdapat 4 kolom numerik dengan tipe data float64 yaitu: temperature, humidity, ph dan rainfall. Ini merupakan fitur numerik.</li><li>Terdapat 1 kolom dengan tipe data object, yaitu: label. Kolom ini merupakan categorical features (fitur non-numerik) dimana kolom ini merupakan target fitur.</li></ul></span></div>

###Distribusi nilai setiap variabel dalam dataset
"""

land_df.describe()

"""#### <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight:**<br>Output kode di atas memberikan informasi statistik pada masing-masing kolom, antara lain:<br><ul><li>count adalah jumlah sampel pada data.</li><li>mean adalah nilai rata-rata.</li><li>std adalah standar deviasi.</li><li>min yaitu nilai minimum setiap kolom.</li><li>25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.</li><li>50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).</li><li>75% adalah kuartil ketiga.</li><li>Max adalah nilai maksimum.</li></ul></span></div>

##**Exploratory Data Analysis - Memeriksa Missing Value dan dan Outliers**

###mengetahui missing value
"""

# Menghitung jumlah data kosong pada setiap kolom
land_df.isnull().sum()

"""#### <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight:**<br>Output kode di atas memberikan informasi bahwa tidak terdapat *missing value* pada dataset</span></div>

###Menangani Outliers

mendeteksi outliers dengan teknis visualisasi data (boxplot). Kemudian kita akan menangani outliers dengan metode IQR.
"""

for fitur in land_df.keys():
  # Selain target dan Id
  if fitur=='quality' or fitur=='Id':
    continue
  sns.boxplot(x=land_df[fitur])
  plt.show()

numeric_df = land_df.select_dtypes(include=['number']) # Select only numerical columns
Q1 = numeric_df.quantile(0.25) # Calculate quantiles on the numerical DataFrame
Q3 = numeric_df.quantile(0.75)
IQR = Q3 - Q1
land_df = land_df[~((land_df[numeric_df.columns] < (Q1 - 1.5 * IQR)) | (land_df[numeric_df.columns] > (Q3 + 1.5 * IQR))).any(axis=1)]
# Cek ukuran dataset setelah kita drop outliers
land_df.shape

for fitur in land_df.keys():
  # Selain target dan Id
  if fitur=='quality' or fitur=='Id':
    continue
  sns.boxplot(x=land_df[fitur])
  plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari hasil deteksi ulang outlier dengan boxplot di atas, didapat bahwa outlier sudah berkurang setelah dibersihkan.</span></div>

## **Exploratory Data Analysis - Univariate Analysis**

###Explorasi atribut data numerical dan categorical
"""

# membagi dataset menjadi 2 bagian yaitu kategorial dan numerik
categorical_features = ['label']
numerical_features = [
                      'N',
                      'P',
                      'K',
                      'temperature',
                      'humidity',
                      'ph',
                      'rainfall'
                      ]

"""### Sebaran/ distribusi data pada fitur target"""

for feature in categorical_features:
    count = land_df[feature].value_counts()
    percent = 100 * land_df[feature].value_counts(normalize=True)
    data = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
    print(f"Distribusi untuk kolom '{feature}':")
    print(data)

    # Plot histogram untuk kolom saat ini
    land_df[feature].value_counts().plot(kind="bar", figsize=(10, 5))
    plt.title(f"Distribusi untuk kolom '{feature}'")
    plt.xlabel(feature)
    plt.ylabel("Jumlah sampel")
    plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Berdasarkan hasil visualisasi dari fitur target 'label' dapat memberikan informasi bahwa dataset sudah seimbang dengan jumlah sampel masing-masing label yaitu 100 sampel, sehingga tidak perlu menyeimbangkan data lagi.</span></div>

###Sebaran/ distribusi data pada setiap fitur numerik
"""

#visualisasi data masing-masing fitur menggunakan histogram plot untuk mengetahui sebaran/distribusi data pada setiap fitur
land_df.hist(bins=50, figsize=(20,15))
plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Berdasarkan hasil visualisasi data diatas, dapat terlihat sebaran atau distribusi data yang ada pada setiap fitur. Termasuk nilai minimum, median, maksimum, Q1, Q3, batas atas dan batas bawah. Selain itu dapat dilihat juga pada beberapa fitur masih terdapat nilai outliers.</span></div>

###Korelasi pada tiap kolom

##Exploratory Data Analysis - Multivariate Analysis

### Mengecek dan Membandingkan rata-rata N, P, K antar label
"""

# Assuming dataset is a pandas DataFrame with columns 'N', 'P', 'K', 'label', etc.
crop_summary = land_df.groupby('label')[['N', 'P', 'K']].mean()

# Menghitung rata-rata kandungan N, P, dan K
average_N = land_df['N'].mean()
average_P = land_df['P'].mean()
average_K = land_df['K'].mean()

# Menampilkan hasil
print(f"Rata-rata Nitrogen (N): {average_N:.2f}%")
print(f"Rata-rata Fosfor (P): {average_P:.2f}%")
print(f"Rata-rata Kalium (K): {average_K:.2f}%")

# Membandingkan nilai rata-rata dengan setiap label
for label, data in crop_summary.iterrows():
    print(f"\nLabel: {label}")
    print(f"Kandungan Nitrogen (N): {data['N']:.2f}% (Rata-rata: {average_N:.2f}%)")
    print(f"Kandungan Fosfor (P): {data['P']:.2f}% (Rata-rata: {average_P:.2f}%)")
    print(f"Kandungan Kalium (K): {data['K']:.2f}% (Rata-rata: {average_K:.2f}%)")

labels = crop_summary.index
N_values = crop_summary['N']
P_values = crop_summary['P']
K_values = crop_summary['K']

x = range(len(labels))

plt.figure(figsize=(10, 6))

# Menambahkan grafik batang dengan warna gradasi biru
plt.bar(x, N_values, width=0.2, label='Nitrogen (N)', align='center', color='#001f3f')  # Biru dongker
plt.bar([i + 0.2 for i in x], P_values, width=0.2, label='Fosfor (P)', align='center', color='#0074D9')  # Biru biasa
plt.bar([i + 0.4 for i in x], K_values, width=0.2, label='Kalium (K)', align='center', color='#7FDBFF')  # Biru muda

# Menambahkan garis rata-rata dengan warna sesuai
plt.axhline(average_N, color='#001f3f', linestyle='dashed', linewidth=1, label='Rata-rata N')
plt.axhline(average_P, color='#0074D9', linestyle='dashed', linewidth=1, label='Rata-rata P')
plt.axhline(average_K, color='#7FDBFF', linestyle='dashed', linewidth=1, label='Rata-rata K')

# Pengaturan sumbu dan label
plt.xlabel('Label Pupuk')
plt.ylabel('Kandungan (%)')
plt.title('Perbandingan Kandungan N, P, K antar Label Pupuk')
plt.xticks([i + 0.2 for i in x], labels, rotation=45)  # Menempatkan label di tengah batang
plt.legend()

plt.tight_layout()
plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br>Hasil visualisasi di atas memberikan informasi mengenai rata-rata kandungan N, P, K terhadap setiap label crop. Dimana dapat dilihat bahwa terdapat beberapa label crop yang membutuhkan lahan dengan kandungan N, P, K tinggi dan beberapa label membutuhkan lahan dengan kandungan N,P,K rendah.</span></div>

### Mengecek dan Membandingkan rata rata tingkat *temperature*, *humidity*, dan *rainfall* antar setiap label
"""

# Mengelompokkan dan menghitung rata-rata untuk temperature, humidity, dan rainfall
climate_summary = land_df.groupby('label')[['temperature', 'humidity', 'rainfall']].mean()

# Menghitung rata-rata keseluruhan untuk temperature, humidity, dan rainfall
average_temperature = land_df['temperature'].mean()
average_humidity = land_df['humidity'].mean()
average_rainfall = land_df['rainfall'].mean()

# Menampilkan hasil rata-rata keseluruhan
print(f"Rata-rata Temperature: {average_temperature:.2f}°C")
print(f"Rata-rata Humidity: {average_humidity:.2f}%")
print(f"Rata-rata Rainfall: {average_rainfall:.2f} mm")

# Membandingkan nilai rata-rata dengan setiap label
for label, data in climate_summary.iterrows():
    print(f"\nLabel: {label}")
    print(f"Temperature: {data['temperature']:.2f}°C (Rata-rata: {average_temperature:.2f}°C)")
    print(f"Humidity: {data['humidity']:.2f}% (Rata-rata: {average_humidity:.2f}%)")
    print(f"Rainfall: {data['rainfall']:.2f} mm (Rata-rata: {average_rainfall:.2f} mm)")

# Asumsi climate_summary sudah dihitung
labels = climate_summary.index
temperature_values = climate_summary['temperature']
humidity_values = climate_summary['humidity']
rainfall_values = climate_summary['rainfall']

x = range(len(labels))

plt.figure(figsize=(10, 6))

# Menambahkan grafik batang untuk temperature, humidity, dan rainfall dengan warna biru gradasi
plt.bar(x, temperature_values, width=0.2, label='Temperature (°C)', align='center', color='#001f3f')  # Biru dongker
plt.bar([i + 0.2 for i in x], humidity_values, width=0.2, label='Humidity (%)', color='#0074D9')  # Biru biasa
plt.bar([i + 0.4 for i in x], rainfall_values, width=0.2, label='Rainfall (mm)', color='#7FDBFF')  # Biru muda

# Menambahkan garis rata-rata untuk masing-masing parameter
plt.axhline(average_temperature, color='#001f3f', linestyle='dashed', linewidth=1, label='Rata-rata Temperature (°C)')
plt.axhline(average_humidity, color='#0074D9', linestyle='dashed', linewidth=1, label='Rata-rata Humidity (%)')
plt.axhline(average_rainfall, color='#7FDBFF', linestyle='dashed', linewidth=1, label='Rata-rata Rainfall (mm)')

# Pengaturan sumbu dan label
plt.xlabel('Label Area')
plt.ylabel('Nilai')
plt.title('Perbandingan Temperature, Humidity, dan Rainfall antar Label Area')
plt.xticks([i + 0.2 for i in x], labels, rotation=45)  # Menempatkan label di tengah batang
plt.legend()

plt.tight_layout()
plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br>Hasil visualisasi di atas memberikan informasi mengenai tingkat temperature, humidity, dan rainfall terhadap setiap label crop. Dimana dapat dilihat bahwa terdapat beberapa label crop yang membutuhkan lahan dengan tingkat temperature, humidity, dan rainfall tinggi dan beberapa label membutuhkan lahan dengan tingkat temperature, humidity dan rainfall rendah.</span></div>

###Korelasi antar fitur numerik
"""

# korelasi antar fitur numerik menggunakan fungsi pairplot
plt.figure(figsize=(19,17))
sns.pairplot(land_df,hue='label', diag_kind='kde',palette='Blues')
plt.show()

# Pilih hanya kolom numerik
numerical_df = land_df.select_dtypes(include=['number'])

# Hitung matriks korelasi
correlation_matrix = numerical_df.corr().round(2)

# Visualisasi heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", size=20)
plt.show()

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br><ul> <li><b>Korelasi Positif Kuat (mendekati 1):</b><br><ul><li><b>P (Fosfor) dan K (Kalium):</b> Memiliki korelasi positif yang sangat kuat (0.74). Ini menunjukkan hubungan linear yang signifikan. Kenaikan nilai P cenderung diikuti kenaikan nilai K, dan sebaliknya.</li><li><b>temperature (Suhu) dan humidity (Kelembaban):</b> Memiliki korelasi positif moderat (0.21). Ada kecenderungan perubahan searah, meski tidak terlalu kuat.</li> </ul></li><li><b>Korelasi Negatif Lemah (mendekati -1):</b><br> <ul><li><b>N (Nitrogen) dan P (Fosfor):</b> Memiliki korelasi negatif yang lemah (-0.23), menunjukkan sedikit kecenderungan berlawanan, tetapi tidak signifikan.</li></ul></li><li><b>Korelasi Sangat Lemah atau Tidak Ada Korelasi (mendekati 0):</b><br><ul><li>Sebagian besar pasangan fitur lainnya menunjukkan korelasi yang sangat lemah, menandakan tidak adanya hubungan linear yang signifikan. Contohnya, hubungan antara N dan *temperature* (0.03) atau antara pH dan *humidity* (-0.01).</li></ul></li><li><b>Implikasi Penting:</b> Korelasi yang kuat antara P dan K mengindikasikan potensi redundansi fitur. Dalam analisis atau pemodelan lebih lanjut, salah satu dari kedua fitur ini mungkin dapat dihilangkan tanpa kehilangan informasi yang signifikan.</li></ul></span></div>

#**Data Preparation**

###Reduksi dimensi dengan Principal Component Analysis (PCA)
"""

sns.pairplot(land_df.loc[:, land_df.columns != 'quality'],
             kind="reg",
             markers="+",
             diag_kind='kde',
             plot_kws={'line_kws': {'color':'red'},
                       'scatter_kws': {'alpha': 0.5}})

"""### Melakukan label encoding pada fitur target (label)"""

from sklearn.preprocessing import LabelEncoder

# Menggunakan LabelEncoder
label_encoder = LabelEncoder()
X = land_df[numerical_features]
y = label_encoder.fit_transform(land_df["label"])

# Membuat dictionary dari hasil transformasi yang valid
label_dict = {}
for i in set(y):  # Hanya iterasi pada nilai yang benar-benar ada
    label_dict[i] = label_encoder.inverse_transform([i])[0]

label_dict

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br>Sebelum melangkah ke tahap pembagian dataset, dilakukan pemisahan antara variabel independen (N, P, K, suhu, kelembaban, pH, curah hujan) sebagai data X dan variabel dependen (label) sebagai data y. Mengingat fitur label pada dataset bersifat non-numerik (kategorikal), diterapkan teknik label encoding untuk mentransformasi data tersebut menjadi representasi numerik yang kompatibel dengan model.</span></div>

## Melakukan pembagian dataset
"""

# melakukan pembagian data X dan y dengan train_test_split
X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2, random_state = 0)
print(f'Total jumlah sample pada dataset: {len(X)}')
print(f'Total jumlah sample pada train dataset: {len(X_train)}')
print(f'Total jumlah sample pada test dataset: {len(X_test)}')

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br>Untuk keperluan pelatihan dan pengujian model, dataset dibagi menjadi dua bagian. Sebanyak 80% data digunakan sebagai data latih, yang terdiri dari 1768 sampel, dan 20% sisanya digunakan sebagai data uji, yang terdiri dari 358 sampel.</span></div>

## Mengatasi outlier pada data train dengan metode LOF (*Local Outlier Factor*)
"""

# mengatasi outlier fungsi LocalOutlierFactor
lof = LocalOutlierFactor().fit_predict(X_train)
mask = lof != -1
X_train, y_train = X_train[mask, :], y_train[mask]

X_train

X_test

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Keterangan**: <br>Melalui proses standarisasi data, dipastikan bahwa seluruh nilai dari fitur-fitur numerik, baik pada data latih maupun data uji, telah ditransformasi ke dalam skala yang seragam.</span></div>

# **Model Development**
"""

# Siapkan dataframe untuk analisis model
df_models = pd.DataFrame(index=['Train MSE', 'Test MSE'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""## K-Nearest Neighbor*"""

# Import necessary libraries
from sklearn.neighbors import KNeighborsRegressor  # Import KNeighborsRegressor
from sklearn.metrics import mean_squared_error  # Import mean_squared_error

# Inisialisasi list_mse sebagai daftar kosong
list_mse = []

# Perulangan untuk mencoba nilai k dari 1 hingga 20
for k in range(1, 21):
    knn = KNeighborsRegressor(n_neighbors=k)  # Inisialisasi model KNeighborsRegressor
    knn.fit(X_train, y_train)  # Melatih model
    y_prediction = knn.predict(X_test)  # Memprediksi nilai untuk data uji
    test_mse = mean_squared_error(y_test, y_prediction)  # Menghitung nilai MSE
    list_mse.append(test_mse)  # Menambahkan nilai MSE ke daftar
    print(f"Nilai MSE untuk k = {k} adalah : {test_mse}")

# Visualisasi hubungan Nilai K terhadap MSE
plt.figure(figsize=(10, 6))
plt.plot(range(1, 21), list_mse, color='blue', marker='o', linestyle='dashed',
         markerfacecolor='red', markersize=10)
plt.title('Visualisasi Nilai K terhadap Mean Squared Error (MSE)', fontsize=14)
plt.xlabel('Nilai K', fontsize=12)
plt.ylabel('Mean Squared Error (MSE)', fontsize=12)
plt.xticks(range(1, 21))  # Pastikan sumbu x hanya memiliki nilai dari 1 sampai 20
plt.tight_layout()
plt.show()

# didapatkan nilai k optimal adalah 1
print("Minimum error:-",min(error_rate)," pada K =",error_rate.index(min(error_rate))+1)

KNN = KNeighborsRegressor(n_neighbors=7)
KNN.fit(X_train, y_train)
df_models.loc['Train MSE', 'KNN'] = mean_squared_error(
    y_pred=KNN.predict(X_train),
    y_true=y_train)

# Inisialisasi dan latih model klasifikasi KNN
knn_classifier = KNeighborsClassifier(n_neighbors=3)  # Ubah ke classifier
knn_classifier.fit(X_train, y_train)

# Prediksi data test
knn_predictions = knn_classifier.predict(X_test)

# Menghasilkan classification report
knn_report = classification_report(y_test, knn_predictions, output_dict=True, target_names=label_encoder.classes_)
report_df = pd.DataFrame(knn_report).transpose()
print(report_df)

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari kode di atas dapat dilihat bahwa model dengan algoritma K-Nearest Neighbor memperoleh nilai akurasi yaitu sebesar 2.0066874207310046 dengan k = 7.</span></div>

#Random Forest
"""

# Membuat model Random Forest untuk klasifikasi
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Melatih model
model.fit(X_train, y_train)

# Prediksi menggunakan model
y_pred = model.predict(X_test)

# Menghitung akurasi
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Inisialisasi dan latih model Random Forest
rf_classifier = RandomForestClassifier(random_state=18)  # Anda bisa menambahkan hyperparameter lain sesuai kebutuhan
rf_classifier.fit(X_train, y_train)

# Prediksi data test
rf_predictions = rf_classifier.predict(X_test)

# Menghasilkan classification report
rf_report = classification_report(y_test, rf_predictions, output_dict=True, target_names=label_encoder.classes_)
report_df = pd.DataFrame(rf_report).transpose()

# Menampilkan classification report dalam bentuk dataframe
print(report_df)

RF = RandomForestRegressor(n_estimators=30, max_depth=16)
RF.fit(X_train, y_train)

df_models.loc['Train MSE', 'RandomForest'] = mean_squared_error(
    y_pred=RF.predict(X_train),
    y_true=y_train)

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari kode di atas dapat dilihat bahwa model dengan algoritma Random Forest memperoleh nilai akurasi yaitu sebesar 0.9971751412429378.</span></div>

# **XGBoost Algorithm**
"""

# Membuat model XGBoost untuk klasifikasi
# model = xgb.XGBClassifier(objective ='multi:softmax', num_class=3)
model = XGBClassifier(objective ='multi:softmax', num_class=3)

# Melatih model
model.fit(X_train, y_train)

# Prediksi menggunakan model
y_pred = model.predict(X_test)

# Menghitung akurasi
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Prediksi menggunakan data test
y_pred = model.predict(X_test)

# Menghasilkan classification report
report = classification_report(y_test, y_pred, output_dict=True)

# Menampilkan classification report dalam bentuk DataFrame
report_df = pd.DataFrame(report).transpose()
print(report_df)

from sklearn.ensemble import AdaBoostRegressor
boosting = AdaBoostRegressor(n_estimators=90, learning_rate=0.2)
boosting.fit(X_train, y_train)

df_models.loc['Train MSE', 'Boosting'] = mean_squared_error(
    y_pred=boosting.predict(X_train),
    y_true=y_train)

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari kode di atas dapat dilihat bahwa model dengan algoritma XGBoost memperoleh nilai akurasi yaitu sebesar 0.9745762711864406.</span></div>

#**Evaluasi Model**

Mengevaluasi model-model tersebut menggunakan data uji dan metrik yang digunakan dalam kasus ini yaitu mean_squared_error. Hasil evaluasi kemudian kita simpan ke dalam df_models.
"""

for name, model in {'KNN': KNN, 'RandomForest': RF, 'Boosting': boosting}.items():
  df_models.loc['Test MSE', name] = mean_squared_error(
      y_pred=model.predict(X_test),
      y_true=y_test)

# Mengecek evaluasi model
display(df_models)

""" Plot hasil evaluasi model dengan bar chart."""

fig, ax = plt.subplots()
df_models.T.sort_values(by='Test MSE', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari gambar di atas, terlihat bahwa, model RandomForest memberikan nilai eror (MSE) yang paling kecil. Sedangkan model algoritma Boosting memiliki eror yang paling besar. Sebelum memutuskan model terbaik untuk melakukan prediksi Quality. Mari kita coba uji prediksi menggunakan beberapa sampel acak (5) pada data uji..</span></div>"""

X_test_df = pd.DataFrame(X_test)
X_sample = X_test_df.sample(5)
dict_result = {
    'index_sample': [],
    'y_true': [],
    'prediksi_KNN': [],
    'prediksi_RF': [],
    'prediksi_Boosting': []
}

# X_sample = X_test.sample(5)
dict_result['index_sample'] = X_sample.index.values
dict_result['y_true'] = [y_test[idx] for idx in dict_result['index_sample']]

for name, model in {'KNN': KNN, 'RF': RF, 'Boosting': boosting}.items():
  dict_result['prediksi_' + name] = model.predict(X_sample)

display(pd.DataFrame(dict_result).set_index('index_sample'))

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>algoritma KNN adalah yang paling mendekati nilai sebenarnya untuk data-data yang ditampilkan.</span></div>

## Perbandingan metriks akurasi antar model
"""

#menghitung nilai akurasi, precision dan recall setiap model
knn_accuracy = round((accuracy_score(y_test, knn_predictions)*100), 2)
rf_accuracy = round((accuracy_score(y_test, rf_predictions)*100), 2)
xgb_accuracy = round((accuracy_score(y_test, xgb_predictions)*100), 2)

knn_precision = round((precision_score(y_test, knn_predictions, average='macro')*100), 2)
rf_precision = round((precision_score(y_test, rf_predictions, average='macro')*100), 2)
xgb_precision = round((precision_score(y_test, xgb_predictions, average='macro')*100), 2)

knn_recall = round((recall_score(y_test, knn_predictions, average='macro')*100), 2)
rf_recall = round((recall_score(y_test, rf_predictions, average='macro')*100), 2)
xgb_recall = round((recall_score(y_test, xgb_predictions, average='macro')*100), 2)

# membat dataframe hasil evaluasi
list_evaluasi= [[knn_accuracy, knn_precision, knn_recall],
                [rf_accuracy, rf_precision, rf_recall],
            [xgb_accuracy, xgb_precision, xgb_recall],]
evaluasi = pd.DataFrame(list_evaluasi,
                        columns=['Accuracy (%)', 'Precision (%)', 'Recall (%)'],
                        index=['K-Nearest Neighbor','Random Forest','XGBoost'])
evaluasi

"""####  <div align="left"><span style="white-space: pre-wrap; font: normal 11pt Arial; line-height: 1.5;">**Insight**: <br>Dari hasil evaluasi di atas dapat memberikan informasi bahwa ketiga model yang dibangun memiliki performa di atas 95%. Dimana dapat dilihat juga bahwa model dengan algoritma Random Forest memiliki performa (nilai akurasi, precision, dan recall) yang lebih baik dari dua model lainnya yaitu model dengan algoritma K-Nearest Neighbor dan XGBoost.</span></div>

#Kesimpulan

Berdasarkan hasil evaluasi model di atas, dapat disimpulkan bahwa model terbaik untuk melakukan rediksi Pemilihan Jenis Tanaman untuk Lahan Pertanian adalah  model Random Forest dapat dianggap sebagai model terbaik untuk digunakan dalam kasus ini
"""